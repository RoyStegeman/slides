\documentclass[aspectratio=169,10pt]{beamer}
\graphicspath{{figures/}} % Setting the graphicspath

% Theme settings
\usetheme{Madrid}
\usecolortheme{default}
\setbeamertemplate{navigation symbols}{}   % removes navigation symbols such as 'next page'
\setbeamertemplate{footline}{}             % remove line with name, date, page nr. 
\setbeamercolor*{frametitle}{bg=white}     % remove background from frametitle
\usepackage{caption}
\captionsetup[figure]{labelformat=empty}% redefines the caption setup of the figures environment in the beamer class.
\setbeamersize{text margin left=20pt,text margin right=10pt}

\usefonttheme[onlymath]{serif}

\definecolor{Red}{rgb}{1,0,0}
\definecolor{Green}{rgb}{0,1,0}
\definecolor{Blue}{rgb}{0,0,1}
\definecolor{Gray}{gray}{0.9}
\definecolor{springgreen}   {cmyk}{0.26, 0   , 0.76, 0   }
\definecolor{olivegreen}    {cmyk}{0.64, 0   , 0.95, 0.40}
\definecolor{emerald}       {cmyk}{1   , 0   , 0.50, 0   }
\definecolor{junglegreen}   {cmyk}{0.99, 0   , 0.52, 0   }
\definecolor{seagreen}      {cmyk}{0.69, 0   , 0.50, 0   }
\definecolor{green}         {cmyk}{1   , 0   , 1   , 0   }
\definecolor{forestgreen}   {cmyk}{0.91, 0   , 0.88, 0.12}
\definecolor{pinegreen}     {cmyk}{0.92, 0   , 0.59, 0.25}
\definecolor{sepia}         {cmyk}{0   , 0.83, 1   , 0.70}
\definecolor{cerulean}      {cmyk}{0.94, 0.11, 0   , 0   }
\definecolor{salmon}        {cmyk}{0   , 0.53, 0.38, 0   }
\definecolor{greenyellow}   {cmyk}{0.15, 0   , 0.69, 0   }
\definecolor{arsenic}       {rgb}{0.23, 0.27, 0.29}
\definecolor{britishracinggreen}{rgb}{0.0, 0.26, 0.15}
\definecolor{oxfordblue}{rgb}{0.0, 0.13, 0.28}
\definecolor{bostonuniversityred}{rgb}{0.8, 0.0, 0.0}
\definecolor{goldenyellow}{rgb}{1.0, 0.87, 0.0}

\definecolor{darkgreen}{rgb}{0.0, 0.5, 0.13}
\definecolor{darkred}{rgb}{0.55, 0.0, 0.0}

\newcommand{\arrowdownunder}{\begin{center}$\big\downarrow$\end{center}\vspace{-0.3cm}}
\newcommand{\mycolutitle}[1]{\vspace{-0.7cm}\begin{center}#1\end{center}\vspace{-0.1cm}}

\newcommand\ballref[1]{%
\tikz \node[circle, shade,ball color=structure.fg,inner sep=0pt,%
  text width=8pt,font=\tiny,align=center] {\color{white}\ref{#1}};
}

%\fontsize{4pt}{5}\selectfont

%======================= import packages =======================
\usepackage{pifont}       % Pi fonts (Digbats, symbol, etc.)
\usepackage{graphicx}     % More options for \includegraphics
\usepackage{tikz}
\usepackage{appendixnumberbeamer} % separate appendix numbering
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{tabularx}



%======================= tikz settings =======================
\usetikzlibrary{shapes, arrows}
\usetikzlibrary{decorations.pathreplacing}
\usetikzlibrary{positioning, calc}
\tikzstyle{fitted} = [rectangle, minimum width=5cm, minimum height=1cm, text centered, draw=black, fill=red!30]
\tikzstyle{operations} = [rectangle, rounded corners, minimum width=2cm,text centered, draw=black, fill=red!30]
\tikzstyle{roundtext} = [rectangle, rounded corners, minimum width=2cm, minimum height=0.8cm, text centered, draw=black, fill=red!30]
\tikzstyle{n3py} = [rectangle, rounded corners, minimum width=3cm, minimum height=1cm, text centered, draw=black, fill=green!30]
\tikzstyle{myarrow} = [thick,->,>=stealth]
\tikzstyle{line} =[draw, -latex']
\tikzstyle{decision} = [diamond, draw, fill=red!20, text width=7.5em, text centered,  inner sep=0pt, minimum height=2em, aspect=4]
\tikzstyle{cloud} = [draw, ellipse,fill=green!20, minimum height=2em]
\tikzstyle{inout} = [rectangle, draw, fill=green!20, text width=9.5em, text centered, rounded corners, minimum height=2em, minimum width=10em]
\tikzstyle{block}=[rectangle, draw, fill=blue!20, text width=9.5em, 
                   text centered, rounded corners, minimum height=2em, 
                   minimum width=10em]



%======================= page numbering =======================
\addtobeamertemplate{navigation symbols}{}{ \usebeamerfont{footline}
  \insertframenumber / \inserttotalframenumber \hspace*{2mm} \\ \vspace*{1mm} 
}


%=================================== colors ===================================
\definecolor{RoyBlue}{RGB}{22, 46, 69}
\definecolor{RoyGrey}{RGB}{64, 88, 128} 

\newcommand{\hlme}[1]{{\color{red}\bf #1}} % highlihgt me

\setbeamercolor{structure}{fg=RoyBlue} % itemize, enumerate, etc
\setbeamercolor{frametitle}{fg=RoyGrey}
 \setbeamercolor{section in head/foot}{bg=RoyBlue}


%======================= add progress dots to headline =======================
\setbeamertemplate{headline}{%
    \begin{beamercolorbox}[ht=4mm,dp=4mm]{section in head/foot}
        \insertnavigation{\paperwidth}
    \end{beamercolorbox}%
}%
\makeatother



%=================================== titlepage ===================================
\title{NNPDF4.0: Towards a new generation of PDFs using ML}
\date{ML4Jets2021, 6 July 2021}
\author{Roy Stegeman}
\institute{University of Milan and INFN Milan}
\titlegraphic{\vspace*{6mm}
    \includegraphics[height=0.8cm]{logos/LOGO-ERC.jpg} \hspace{10mm}
	\includegraphics[height=0.8cm]{logos/n3pdflogo_noback.png} \hspace{10mm}
	\includegraphics[height=0.6cm]{logos/nnpdf_logo_official.pdf} \hspace{10mm}
	\includegraphics[height=0.8cm]{logos/Logo_Università_degli_Studi_di_Milano(not_mandatory).png}
	\includegraphics[height=0.8cm]{logos/INFN_logo.png}
    \vspace*{5mm} \\
	\centering{ 
	\fontsize{7.0pt}{0.0pt}\selectfont This project has received funding from the European Union’s Horizon 2020 \\	
    \vspace*{-1mm}
	research and innovation programme under grant agreement No 740006.
	}
}







\begin{document}


{
\setbeamertemplate{headline}{} % remove headline from titlepage
\begin{frame}
  \titlepage
\end{frame}
}



%\begin{frame}
%\frametitle{Outline}
%\tableofcontents
%\end{frame}


\section{The NNPDF methodology}

\begin{frame}
 \frametitle{The path to NNPDF4.0}
 \footnotesize
 \begin{block}{}
  \centering
  Improving {\textcolor{red}{data}}, {\textcolor{blue}{theory}} and {\textcolor{forestgreen}{methodology}}\\
 \end{block}
 \scriptsize
 \renewcommand*{\arraystretch}{1.2}
 \begin{tabularx}{\textwidth}{lXr}
  06/2017 & {\bf NNPDF3.1}                                                              
          & {\tiny{[{\textcolor{salmon}{EPJ\,C77\,(2017)\,663}}]}}\\
  10/2017 & \textcolor{blue}{NNPDF3.1sx}: {\scriptsize PDFs with small-$x$ resummation}                                                
          & {\tiny{[{\textcolor{salmon}{EPJ\,C78\,(2018)\,321}}]}}\\
  12/2017 & \textcolor{blue}{NNPDF3.1luxQED}: {\scriptsize consistent photon PDF \`a la luxQED}                                            
          & {\tiny{[{\textcolor{salmon}{SciPost\,Phys.\,5\,(2018)\,008}}]}}\\
  02/2018 & \textcolor{red}{NNPDF3.1+ATLASphoton}: {\scriptsize inclusion of direct photon data}                                       
          & {\tiny{[{\textcolor{salmon}{EPJ\,C78\,(2018)\,470}}]}}\\
  12/2018 & \textcolor{forestgreen}{NNPDF3.1alphas}: {\scriptsize $\alpha_s$ from a correlated-replica method}                                     
          & {\tiny{[{\textcolor{salmon}{EPJ\,C78\,(2018)\,408}}]}}\\
  12/2018 & \textcolor{forestgreen}{NNPDF3.1nuc}: {\scriptsize heavy ion nuclear uncertainties in a fit}                                        
          & {\tiny{[{\textcolor{salmon}{EPJ\,C79\,(2019)\,282}}]}}\\
  05/2019 & \textcolor{forestgreen}{NNPDF3.1th}: {\scriptsize missing higher-order uncertainties in a fit}                                         
          & {\tiny{[{\textcolor{salmon}{EPJ\,C79\,(2019)\,838; ibid.\,931}}]}}\\
  07/2019 & \textcolor{forestgreen}{Gradient descent and hyperoptimisation in PDF fits} 
          & {\tiny{[{\textcolor{salmon}{EPJ\,C79\,(2019)\,676}}]}}\\
  12/2019 & \textcolor{red}{NNPDF3.1singletop}: {\scriptsize inclusion of single top $t$-channel data}                                          
          & {\tiny{[{\textcolor{salmon}{JHEP\,05\,(2020)\,067}}]}}\\
  05/2020 & \textcolor{red}{NNPDF3.1dijets}: {\scriptsize comparative study of single- and di-jets}                                             
          & {\tiny{[{\textcolor{salmon}{EPJ\,C80\,(2020)\,797}}]}}\\
  06/2020 & \textcolor{blue}{Positivity of $\overline{\rm MS}$ PDFs}                    
          & {\tiny{[{\textcolor{salmon}{JHEP\,11\,(2020)\,129}}]}}\\
  08/2020 & \textcolor{forestgreen}{PineAPPL}: {\scriptsize fast evaluation of EW$\times$QCD corrections}                                           
          & {\tiny{[{\textcolor{salmon}{JHEP\,12\,(2020)\,108}}]}}\\
  08/2020 & \textcolor{red}{NNPDF3.1strangeness}: {\scriptsize assessment of strange-sensitive data}                                        
          & {\tiny{[{\textcolor{salmon}{EPJ\,C80\,(2020)\,1168}}]}}\\
  11/2020 & \textcolor{forestgreen}{NNPDF3.1deu}: {\scriptsize deuteron uncertainties in a fit}                                        
          & {\tiny{[{\textcolor{salmon}{EPJ\,C81\,(2021)\,37}}]}}\\
  03/2021 & \textcolor{forestgreen}{Future tests}                                       
          & {\tiny{[{\textcolor{salmon}{arXiv:2103.08606}}]}}\\
  2021    & {\bf NNPDF4.0}                                                              
          & {\tiny{[{\textcolor{salmon}{to appear}}]}}\\
 \end{tabularx}
\end{frame}


%\begin{frame}{PDFs as an ML problem: the NNPDF approach}
%   	Why use machine learning for PDF determination?
%    \begin{itemize}
%        \item Unknown functional form which needs to be inferred from data
%        \item Well defined input and output
%        \item Unique: learning uncertainties
%    \end{itemize}
%\begin{center}
%\includegraphics[width=0.7\textwidth]{intro/MC_to_uncertainty}
%\end{center}
%\end{frame}


%\begin{frame}{NNPDF3.1 methodology}
%\begin{columns}
%\column{0.48\linewidth}
%    \begin{itemize}
%        \item Genetic algorithm for optimization
%        \item Custom \texttt{c++} code
%        \item Manual parameter tuning
%    \end{itemize}
%\column{0.48\linewidth}
%    Reasons for modernization: 
%        \begin{itemize}
%            \item \texttt{Python} for easier development
%            \item New hardware and libraries for reduction of fit time
%            \item[{$\Rightarrow$}] Speed-up of research
%        \end{itemize}
%\end{columns}
%\end{frame}
%
%
%\section{NNPDF4.0 methodology}
%
%\begin{frame}{NNPDF4.0 model}{For more information see  \href{https://arxiv.org/pdf/1907.05075}{\color{blue} EPJ\,C79\,(2019)\,676}}
%
%\begin{figure}[t]
%	\centering
%	\resizebox{0.8\textwidth}{!}{%
%		\begin{tikzpicture}[node distance = 1.0cm]\scriptsize
%		% Input node
%		\node (xinput) {$\{\mathrm{xgrid}_n\}$};
%
%		% PDF basis
%		\coordinate [right = 1.5cm of xinput] (NNghost) {};
%		\node[fitted, above = 1.0cm of NNghost, minimum width=1.7cm, minimum height=0.7cm] (pdf) { Neural Net};
%		\node[fitted, below = 1.0cm of NNghost, minimum width=1.7cm, minimum height=0.7cm] (preproc) { $x^{\alpha}$ $(1-x)^{\beta}$};
%		\node[above = 0.6cm of pdf, minimum width=1.7cm, minimum height=0.7cm] (fform) { $\mathrm{PDF}=Ax^\alpha(1-x)^\beta NN(x)$};
%
%		% PDF production
%		\node[operations, fill=violet!40, minimum width=1.2cm, minimum height=0.7cm, right = 1.5cm of NNghost]
%		    (fitbasis) {$\overline{\mathrm{PDF}}_n$};
%		\node[operations, fill=violet!40, minimum width=1.2cm, minimum height=0.7cm, right = 0.6cm of fitbasis]
%		    (normalizer) {normalization};
%
%		% PDFs 1 to n
%		\node[right = 0.9cm of normalizer] (pdfdots) {\vdots};
%		\node[above = 0.7cm of pdfdots] (pdf1) {PDF$_1$};
%		\node[below = 0.7cm of pdfdots] (pdfn) {PDF$_n$};
%
%		% Convolutions 1 to n
%		\node[right = 0.2cm of pdf1] (conv1) {$\otimes$};
%		\node[right = 0.2cm of pdfn] (convn) {$\otimes$};
%		\node at ($(conv1)!0.5!(convn)$) (convdots) {$\otimes$};
%
%		% FK Tables 1 to n
%		\node[blue, right = 0.6cm of conv1] (f1) {$\hat{\sigma}_1$};
%		\node[blue, right = 0.6cm of convn] (fn) {$\hat{\sigma}_n$};
%		\node[blue] at ($(f1)!0.5!(fn)$) (fd) {\vdots};
%		\draw[draw=blue, rounded corners] ($(f1.north west)+(-0.1, 0.2)$) rectangle ($(fn.south east)+(0.1,-0.2)$);
%        \node[above = 0.6cm of f1] (theory) {Theory};
%        \coordinate [above = 0.2cm of f1] (theoryarrow) {};
%
%		% Observables
%		\node[right = 0.5 cm of f1] (o1) {$\mathcal{O}_{1}$};
%		\node[right = 0.5 cm of fn] (on) {$\mathcal{O}_{n}$};
%		\node at ($(o1)!0.5!(on)$) (od) {\vdots};
%		\node[above = 0.9cm of o1] (observables) {Observables};
%		\coordinate [above = 0.2cm of o1] (observablearrow) {};
%
%		% Tr/Vl split
%		\node[operations, right = 0.5cm of od, minimum width = 1.2cm, text width=1cm, minimum height=0.7cm]
%		(trvl) {Tr/Vl split};
%		\coordinate [right = 1.0cm of trvl] (ending) {};
%		\path let \p1 = (ending), \p2 = (pdf)
%		    in node at (\x1,\y2) [n3py, minimum width = 1.2cm, minimum height=0.7cm] (tr) {$\chi^{2}_\text{tr}$};
%		\path let \p1 = (ending), \p2 = (preproc)
%		    in node at (\x1,\y2) [n3py, minimum width = 1.2cm, minimum height=0.7cm] (vl) {$\chi^{2}_\text{vl}$};
%
%		% Arrows!
%		\draw[myarrow] (xinput) -- (pdf);
%		\draw[myarrow] (xinput) -- (preproc);
%		\draw[myarrow] (pdf) -- (fitbasis);
%		\draw[myarrow] (preproc) -- (fitbasis);
%		\draw[myarrow] (fitbasis) -- (normalizer);
%
%		\draw[myarrow] (pdf1) -- (conv1);
%		\draw[myarrow] (pdfn) -- (convn);
%		\draw[myarrow] (conv1) -- ($(f1.west)-(0.2,0.0)$) ;
%		\draw[myarrow] (convn) -- ($(fn.west)-(0.2,0.0)$) ;
%		\draw[myarrow] ($(f1.east)+(0.2,0.0)$) -- (o1);
%		\draw[myarrow] ($(fn.east)+(0.2,0.0)$) -- (on);
%
%		\draw[myarrow] (trvl) -- (tr);
%		\draw[myarrow] (trvl) -- (vl);
%		
%		\draw[myarrow] (theory) -- (theoryarrow);
%		\draw[myarrow] (observables) -- (observablearrow);
%		
%		% Braces
%		\draw[decorate, decoration={brace}, thick] (pdfn.south west) -- (pdf1.north west);
%		\draw[decorate, decoration={brace},thick] (o1.north east) -- (on.south east);
%		\end{tikzpicture}
%	}
%\end{figure}
%
%\textbf{Main changes:}
%\begin{itemize}
%    \item Gradient Descent using \texttt{TensorFlow}
%    \item Modular design
%    \item Automated selection of fit parameters
%\end{itemize}
%
%\end{frame}


%\begin{frame}{Improved performance}
%\begin{table}
%   \renewcommand{\arraystretch}{1.50}
%	\centering
%	\begin{tabular}{c | c | c | c} \toprule
%	  & NNPDF3.1  & NNPDF4.0 (CPU) & NNPDF4.0  (GPU) \\
%          \midrule
%	  Fit timing per replica    & 15.2 h        & 38 min        & 6.6 min \\ \hline
%           Speed up factor    & 1        &  24      & 140 \\ \hline
%	  RAM use &  1.5 GB          &  6.1 GB                 & NA  \\ \bottomrule
%	\end{tabular}
%\end{table}
%    \begin{itemize}
%        \item easier development
%        \item faster, modularity allows use of new technologies
%        \item conclusion: faster research, able to test many parameter configurations
%    \end{itemize}
%\end{frame}


\begin{frame}[t]{Methodological differences}
    \frametitle{Key differences with respect to the 3.1 methodology}
    \footnotesize
    \begin{columns}[t]
        \column{0.5\linewidth}
            \mycolutitle{NNPDF 3.1 code}
            \begin{list}{\color{darkred} $\rightarrow$}{}
                \item C++ monolithic codebase
                 \item In-house Machine Learning optimization framework
                %\item Genetic Algorithm optimizer
                %\item One network per flavour
                \item Fitting times of up to several days
                \item  Genetic Algorithm optimizer
                \item Fit parameters manually chosen
            \end{list}
        \column{0.5\linewidth}
            \mycolutitle{NNPDF 4.0 code}
            \begin{list}{\color{darkgreen} $\rightarrow$}{} 
                \item Python modular codebase 
                \item Freedom to use external libraries \\ (default: \texttt{TensorFlow})
                %\item Gradient Descent optimization
                %\item One network for all flavours
                \item Results available in about an hour
                \item Gradient Descent optimization
                \item Fit parameters chosen automatically (hyperparameter scan)
            \end{list}
    \end{columns}
\end{frame}


\begin{frame}{Overfitting}
Using the validation set $\chi^2$ as figure of merit leads to overfitting:
\begin{center}
\includegraphics[width=0.4\textwidth]{methodology/overfit_nnpdf31}
\end{center}
    \begin{itemize}
        \item NNPDF3.1 wiggles are finite size effects that vanish as $N_\mathrm{rep}$ grows
        \item NNPDF4.0 overfitting due to training-validation data correlations 
        \item We need to tune model parameters without introducing bias
    \end{itemize}
\end{frame}


\begin{frame}{Removing overfitting: k-fold cross-validation}
\begin{columns}
\column{0.48\linewidth}
To solve the problem of overfitting we employ \textbf{k-fold cross-validation}:
\begin{enumerate}
    \item Divide the data into $k$ subsets
    \item \label{ite:2} Pick a hyperparameter setup
    \item Perform fit to the other $k-1$ sets
    \item Calculate figure of merit: the average $\chi^2$ of the $k$ non-fitted sets
    \item Repeat from step~\ref{ite:2} to optimize the figure of merit
\end{enumerate}


\column{0.48\linewidth}
Using k-fold cross-validation for model selection:

\includegraphics[width=0.8\textwidth]{methodology/no_overfit}

\begin{itemize}
    \item No overfitting
    \item Increased stability
    \item Reduced uncertainties 
\end{itemize}
\end{columns}
\end{frame}



\section{Uncertainty validation}

\begin{frame}{Trusting uncertainties outside the data region}

\begin{itemize}
        \item The improved methodology and extended dataset result in a reduction of the PDF uncertainties.
        \item What about the kinematic regions for which no data is available?
\end{itemize}

\begin{columns}
    \column{0.48\linewidth}
    \textbf{Idea:}
    \begin{enumerate}
    \item Take a historic dataset \\ e.g. pre-HERA or pre-LHC
    \item Perform fit
    \item Compare predictions to ``future'' data
    \end{enumerate}

    \column{0.48\linewidth}
     \includegraphics[width=0.9\textwidth]{future_test/NNPDF31_vs_NNPDF40}
\end{columns}
\end{frame}


\begin{frame}[t]{Future tests}{For more information see \href{https://arxiv.org/pdf/2103.08606.pdf}{\color{blue} arxiv:2103.08606}}

    \begin{columns}
        \column{0.60\linewidth}
        \centering
        \includegraphics[width=0.7\textwidth, height=0.7\textheight]{future_test/kincov.png}
        \column{0.46\linewidth}
        \vspace{-1.7cm}
        \only<1>{
            \begin{table}
                \tiny
                \centering
                \caption*{\scriptsize $\chi^{2}/N$ (only exp. covmat)}
                \begin{tabular}{c | c c c} \toprule
                    (dataset) & NNPDF4.0 & pre-LHC & pre-Hera  \\ \midrule
                    pre-HERA  & 1.09 & 1.01 & 0.90 \\
                    pre-LHC   & 1.21 & 1.20 & \hlme{23.1} \\
                    NNPDF4.0  & 1.29 & \hlme{3.30} & \hlme{23.1} \\
                    \bottomrule
                \end{tabular}
            \end{table}
        }
        \only<2>{
            \begin{table}
                \tiny
                \centering
                \caption*{\scriptsize $\chi^{2}/N$ (exp. and PDF covmat)}
                \begin{tabular}{c | c c c} \toprule
                    (dataset) & NNPDF4.0 & pre-LHC & pre-Hera  \\ \midrule
                    pre-HERA  &  & & 0.86 \\
                    pre-LHC   &  & 1.17 & \hlme{1.22} \\
                    NNPDF4.0  & 1.12 & \hlme{1.30} & \hlme{1.38} \\
                    \bottomrule
                \end{tabular}
            \end{table}
        }


        \includegraphics[width=0.9\textwidth]{future_test/diffu}
    \end{columns}
        \only<2>{\small The total uncertainty increases, and accommodates for difference between predictions and new data.}
\end{frame}



\section{Methodology correlations}

\begin{frame}{Self-correlation of PDF sets}
    	\begin{columns}[t]
        	\column{0.58\linewidth}
        	\vspace*{-0.8cm}
        	
		 Is the data-induced correlation between PDF sets based on the same NNPDF methodology and underlying data 100\%?

        	\vspace{0.2cm}

        \begin{block}{data-induced correlation}
        Data-induced correlation is calculated using PDF pairs fitted to the same data replicas.
        \end{block}
        	
        	\vspace{0.2cm}

			No, the data-induced correlation is not 100\%. This is a result of uncorrelated functional uncertainties.

		\vspace{0.2cm}
			\only<2>{If the data-induced correlation is higher, this means the functional uncertainty is smaller if compared to the data uncertainty.}

        	\column{0.38\linewidth}
        	\vspace*{-1cm}
        		\begin{center}
        		\begin{figure}
            		\includegraphics<1>[width=\textwidth]{corr/nnpdf31_corr.pdf}
            		\includegraphics<2>[width=\textwidth]{corr/nnpdf31&40_corr.pdf}
            		\vspace{-0.9cm}
            		\caption{\tiny PDF-PDF self-correlation between two PDF sets based on the same NNPDF methodology and data, but different (random) initialization. }        		
			\end{figure}
			\end{center}

    	\end{columns}
\end{frame}


\begin{frame}{Combination of PDF sets}
    	\begin{columns}[t]
        	\column{0.58\linewidth}

			At present the PDF4LHC combination method is a simple averaging. 

        	\vspace{0.2cm}

			Can we achieve a more precise results by including underlying data-induced correlations?

        	\vspace{0.2cm}

			No, this can lead to arbitrarily small uncertainties.

       	\column{0.38\linewidth}
       	\vspace{-1.5cm}
       	\begin{center}
       		\includegraphics[height=0.9\textheight]{corr/ratio_2.pdf}
       	\end{center}
			
    	\end{columns}
\end{frame}


\section{Conclusions}


\begin{frame}{Summary}
    \begin{itemize}
        \item Faster and more stable results
        \item Systematic parameter selection 
        \item Faithful reduction of uncertainties
        \item Correlations can be used to assess the efficiency of the methodology
        \vspace*{1em}
        \item NNPDF code will be made publicly available with documentation
    \end{itemize}
\end{frame}



\input{backup}










\end{document}
